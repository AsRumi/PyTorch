{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM9a0LjS07u1rGLCyF/5Zgl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AsRumi/PyTorch/blob/main/PyTorch_Tutorial_00.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "pPC6ZRS8WWBp",
        "outputId": "79b3eb1c-0e73-4118-b34b-cfcbdd3cd17c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.5.1+cu121'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import torch\n",
        "torch.__version__"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_scalar = torch.tensor(10) # A scalar is also known as a 0-dimension tensor.\n",
        "print(f\"Value: {my_scalar.item()}\\nDimensions: {my_scalar.ndim}\") # Use .item() to get the value of the tensor."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-R6P0XXOWaym",
        "outputId": "256fd538-958d-46e5-c855-ed81edb519e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Value: 10\n",
            "Dimensions: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_vector = torch.tensor([3, 4, 6, 7])\n",
        "print(f\"Value: {my_vector}\\nDimensions: {my_vector.ndim}\\nShape: {my_vector.shape} # Shape gives you information on how the elements inside the tensor are arranged.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lbl56Q2fX-Xd",
        "outputId": "f081a9fa-ebb4-4c2c-f78a-fb6ceb253c99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Value: tensor([3, 4, 6, 7])\n",
            "Dimensions: 1\n",
            "Shape: torch.Size([4]) # Shape gives you information on how the elements inside the tensor are arranged.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For this tensor: my_vector = torch.tensor([3, 4, 6, 7])\n",
        "\n",
        "You can easily find out its dimension by counting the square brackets on one side.\n",
        "\n",
        "The shape is 4 because there are 4 elements.\n",
        "\n",
        "Let us look at a matrix now:"
      ],
      "metadata": {
        "id": "8_cKT5nrZlse"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MATRIX = torch.tensor([[7, 8],\n",
        "                       [9, 10]])\n",
        "print(f\"Value: {MATRIX}\\nDimensions: {MATRIX.ndim}\\nShape: {MATRIX.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8W-C_9T-YnHm",
        "outputId": "62c3617c-d4b3-43e9-d89a-297306e11c89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Value: tensor([[ 7,  8],\n",
            "        [ 9, 10]])\n",
            "Dimensions: 2\n",
            "Shape: torch.Size([2, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Shape here is torch.Size([2, 2]) because the matrix is 2 elements long and each element is 2 elements deep."
      ],
      "metadata": {
        "id": "_0Ahae79aC-e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TENSOR = torch.tensor([[[1, 2, 3],\n",
        "                        [3, 6, 9],\n",
        "                        [2, 4, 5]]])\n",
        "print(f\"Values: {TENSOR}\\nDimensions: {TENSOR.ndim}\\nShape: {TENSOR.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3HguFHnrZ5al",
        "outputId": "ea496d97-af89-4ea7-98f9-7cc87f13b892"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Values: tensor([[[1, 2, 3],\n",
            "         [3, 6, 9],\n",
            "         [2, 4, 5]]])\n",
            "Dimensions: 3\n",
            "Shape: torch.Size([1, 3, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Shape of the above tensor is: torch.Size([1, 3, 3]) because there is one array that is an array of 3 arrays, and in each of those arrays, there are 3 elements.\n",
        "\n",
        "By convention, MATRICES and TENSORS are capital letters and scalars and vectors are small letters.\n",
        "\n",
        "Let us see how to create tensors of random values:"
      ],
      "metadata": {
        "id": "PpnKoWqjau6o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "RANDOM_TENSOR = torch.rand(size = (3, 4))\n",
        "print(RANDOM_TENSOR)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lwCKQGGMaWZ9",
        "outputId": "820e47ce-8b67-4b6e-a930-9f3c6cbf2388"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.7847, 0.6667, 0.0871, 0.7380],\n",
            "        [0.9234, 0.6446, 0.4809, 0.2892],\n",
            "        [0.0010, 0.7478, 0.6425, 0.4239]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "RANDOM_IMAGE = torch.rand(size = (3, 150, 150))\n",
        "print(RANDOM_IMAGE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sRGGXB98czv1",
        "outputId": "7f5c044a-482f-46b6-96ed-8870011c659e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[0.7030, 0.0290, 0.7005,  ..., 0.2096, 0.5990, 0.4417],\n",
            "         [0.2599, 0.7018, 0.8359,  ..., 0.9673, 0.7879, 0.2665],\n",
            "         [0.6850, 0.8391, 0.8864,  ..., 0.5404, 0.9216, 0.4953],\n",
            "         ...,\n",
            "         [0.6295, 0.7250, 0.7176,  ..., 0.2059, 0.4555, 0.6781],\n",
            "         [0.8312, 0.9165, 0.8854,  ..., 0.3438, 0.7061, 0.9960],\n",
            "         [0.9499, 0.7638, 0.4621,  ..., 0.8087, 0.2263, 0.9102]],\n",
            "\n",
            "        [[0.7198, 0.0677, 0.7822,  ..., 0.0637, 0.3627, 0.7509],\n",
            "         [0.5257, 0.0658, 0.5591,  ..., 0.7355, 0.5196, 0.6017],\n",
            "         [0.3362, 0.6790, 0.2397,  ..., 0.2857, 0.8156, 0.7435],\n",
            "         ...,\n",
            "         [0.2234, 0.6910, 0.4790,  ..., 0.6760, 0.1123, 0.8314],\n",
            "         [0.6164, 0.2266, 0.7327,  ..., 0.6164, 0.8318, 0.9846],\n",
            "         [0.8163, 0.2687, 0.1712,  ..., 0.8506, 0.9791, 0.8769]],\n",
            "\n",
            "        [[0.4478, 0.1770, 0.4997,  ..., 0.5644, 0.0091, 0.2000],\n",
            "         [0.7956, 0.4916, 0.3361,  ..., 0.4644, 0.0875, 0.9191],\n",
            "         [0.7098, 0.1668, 0.9279,  ..., 0.1078, 0.2787, 0.0053],\n",
            "         ...,\n",
            "         [0.4984, 0.8759, 0.5688,  ..., 0.7531, 0.2449, 0.4419],\n",
            "         [0.5996, 0.1549, 0.7284,  ..., 0.6080, 0.6234, 0.4412],\n",
            "         [0.9911, 0.6942, 0.6886,  ..., 0.9699, 0.5418, 0.1490]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a tensor of all zeros\n",
        "zeros = torch.zeros(size=(3, 4))\n",
        "print(zeros, zeros.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HVdZ8Z6Pc_ok",
        "outputId": "1b21b7cd-1288-4ca1-cd1d-cc5a0ffd8ea9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0.]]) torch.float32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a tensor of all ones\n",
        "ones = torch.ones(size=(3, 4))\n",
        "print(ones, ones.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m6fTewABdLhk",
        "outputId": "05c5e22f-ad1e-4c51-e4dd-069d38fc62de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.]]) torch.float32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a range of values 0 to 10\n",
        "zero_to_ten = torch.arange(start = 0, end = 10, step = 1)\n",
        "print(zero_to_ten)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9aVe8g_6dRkc",
        "outputId": "82febfa4-f522-4018-89b7-e61b0cadcefe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Can also create a tensor of zeros similar to another tensor\n",
        "ten_zeros = torch.zeros_like(input=zero_to_ten) # will have same shape of zero_to_ten\n",
        "print(ten_zeros)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3x7puFLRdhFE",
        "outputId": "317d5779-72e1-4515-e4ff-861b0c7b3034"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tensors also have datatypes: 16, 32, 64-bit float || 8, 16, 32, 64-bit integer\n",
        "\n",
        "The more precise a tensor is (more number of bits), the more accurate your machine learning algorithm will be, however, also will take up a lot of resources and time during training on these tensors.\n",
        "\n",
        "torch.float | torch.float32 - 32 bit float\n",
        "\n",
        "torch.half | torch.float16 - 16 bit float\n",
        "\n",
        "torch.double | torch.float64 - 64 bit float\n",
        "\n",
        "By default PyTorch creates tensors of 32 bit floating datatype, if you want to change this behavior, use the \"dtype\" parameter when declaring a tensor."
      ],
      "metadata": {
        "id": "PZPiM3AKOx7F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Default datatype for tensors is float32\n",
        "float_32_tensor = torch.tensor([3.0, 6.0, 9.0],\n",
        "                               dtype=None, # defaults to None, which is torch.float32 or whatever datatype is passed\n",
        "                               device=None, # defaults to None, which uses the default tensor type\n",
        "                               requires_grad=False) # if True, operations performed on the tensor are recorded\n",
        "\n",
        "float_32_tensor.shape, float_32_tensor.dtype, float_32_tensor.device"
      ],
      "metadata": {
        "id": "22cvRx00drP0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3a5dde7-6a98-4220-81a4-4e649dec1c38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([3]), torch.float32, device(type='cpu'))"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aside from shape issues (tensor shapes don't match up), two of the other most common issues you'll come across in PyTorch are datatype and device issues.\n",
        "\n",
        "For example, one of tensors is torch.float32 and the other is torch.float16 (PyTorch often likes tensors to be the same format).\n",
        "\n",
        "Or one of your tensors is on the CPU and the other is on the GPU (PyTorch likes calculations between tensors to be on the same device)."
      ],
      "metadata": {
        "id": "GXAYlqlJQNZR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 16 bit floating tensor:\n",
        "float_16_tensor = torch.tensor([3.0, 6.0, 9.0],\n",
        "                               dtype = torch.float16) # torch.half would also work\n",
        "\n",
        "float_16_tensor.dtype, float_16_tensor.device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CVV59IrJQDZm",
        "outputId": "d4d276f7-405b-4feb-a193-e479bae52992"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.float16, device(type='cpu'))"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Most common attributes you'll want to find out about tensors are:\n",
        "\n",
        "shape - what shape is the tensor? (some operations require specific shape rules)\n",
        "\n",
        "dtype - what datatype are the elements within the tensor stored in?\n",
        "\n",
        "device - what device is the tensor stored on? (usually GPU or CPU)"
      ],
      "metadata": {
        "id": "ICe8k-NjQcaz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "float_32_tensor.shape, float_32_tensor.dtype, float_32_tensor.device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lA1DWjW6QTcV",
        "outputId": "ee7ac791-c6f3-4694-80f6-f27a033d082c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([3]), torch.float32, device(type='cpu'))"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Addition (+), subtraction (-), mutliplication (*) of tensors."
      ],
      "metadata": {
        "id": "WfNbhsYMQ7Jr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a tensor of values and add a number to it\n",
        "tensor = torch.tensor([1, 2, 3])\n",
        "tensor + 10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jSGB3H9pQn-k",
        "outputId": "88c591ca-5609-46f6-98db-0b883a9fabb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([11, 12, 13])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Multiply it by 10\n",
        "tensor * 10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QYkYenX4Q_Bs",
        "outputId": "e585eb92-bbd8-4aa8-e9b6-b2dae409e973"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([10, 20, 30])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Values inside the tensor don't change unless they're reassigned."
      ],
      "metadata": {
        "id": "byO1ogXkRKmy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Subtract and reassign\n",
        "tensor = tensor - 10\n",
        "tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "07h8EhGgRBuE",
        "outputId": "a79245ae-223f-495d-d01c-8b538d01d1c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-9, -8, -7])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor = tensor + 10\n",
        "tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6rBa4KSFRN2M",
        "outputId": "73641235-45de-478e-98b2-0a843c095e5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "PyTorch also has a bunch of built-in functions like torch.multiply() and torch.add() to perform basic operations."
      ],
      "metadata": {
        "id": "jHay8Dz6RWVH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ten_times_tensor = torch.multiply(tensor, 10)\n",
        "ten_times_tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pslnPnyqRUoE",
        "outputId": "8866ba50-6b6d-431b-c075-e5e8f22a060c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([10, 20, 30])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Element-wise multiplication (each element multiplies its equivalent, index 0->0, 1->1, 2->2)\n",
        "print(tensor, \"*\", tensor)\n",
        "print(\"Equals:\", tensor * tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bwDNbguvRbI8",
        "outputId": "c6b61a84-e2e1-4995-8e44-50cd118f9c02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 2, 3]) * tensor([1, 2, 3])\n",
            "Equals: tensor([1, 4, 9])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Matrix Multiplication\n",
        "\n",
        "PyTorch implements matrix multiplication functionality in the torch.matmul() method.\n",
        "\n",
        "The main two rules for matrix multiplication to remember are:\n",
        "\n",
        "The inner dimensions must match:\n",
        "\n",
        "(3, 2) @ (3, 2) won't work\n",
        "\n",
        "(2, 3) @ (3, 2) will work\n",
        "\n",
        "(3, 2) @ (2, 3) will work\n",
        "\n",
        "The resulting matrix has the shape of the outer dimensions:\n",
        "\n",
        "(2, 3) @ (3, 2) -> (2, 2)\n",
        "\n",
        "(3, 2) @ (2, 3) -> (3, 3)"
      ],
      "metadata": {
        "id": "A6FfqmJfR3g-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Matrix multiplication\n",
        "matrix_multiplied_tensor = torch.matmul(tensor, tensor)\n",
        "print(f\"{tensor} @ {tensor}\\nEquals: {matrix_multiplied_tensor}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qtX0ZWcgRyvM",
        "outputId": "2683fc8c-bf8d-468c-b27e-c96da6775689"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 2, 3]) @ tensor([1, 2, 3])\n",
            "Equals: 14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# Matrix multiplication by hand\n",
        "# (avoid doing operations with for loops at all cost, they are computationally expensive)\n",
        "value = 0\n",
        "for i in range(len(tensor)):\n",
        "  value += tensor[i] * tensor[i]\n",
        "value"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GWysjy4USgmD",
        "outputId": "0808932d-e5d6-470d-e1f2-57b7782af672"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 708 µs, sys: 1 ms, total: 1.71 ms\n",
            "Wall time: 7.76 ms\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(14)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "torch.matmul(tensor, tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iOYCrF0-Szd7",
        "outputId": "1fde4dcd-4e12-42b3-8f3b-eb380f701737"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 80 µs, sys: 9 µs, total: 89 µs\n",
            "Wall time: 93.2 µs\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(14)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Because much of deep learning is multiplying and performing operations on matrices and matrices have a strict rule about what shapes and sizes can be combined, one of the most common errors you'll run into in deep learning is shape mismatches.\n",
        "\n",
        "One of the ways to make matrices compatible for matrix multiplication is to transpose the matrices."
      ],
      "metadata": {
        "id": "6dwBd815TAxx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_A = torch.tensor([[1, 2],\n",
        "                         [3, 4],\n",
        "                         [5, 6]], dtype=torch.float32)\n",
        "\n",
        "tensor_B = torch.tensor([[7, 10],\n",
        "                         [8, 11],\n",
        "                         [9, 12]], dtype=torch.float32)\n",
        "\n",
        "print(tensor_A)\n",
        "print(tensor_B)\n",
        "print(\"These are not compatible for matrix multiplication, but transposing one of these will favor.\")\n",
        "print(tensor_B.T)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3uRgnboTS2hb",
        "outputId": "9824af78-d844-4828-b11f-cab9c6be536b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 2.],\n",
            "        [3., 4.],\n",
            "        [5., 6.]])\n",
            "tensor([[ 7., 10.],\n",
            "        [ 8., 11.],\n",
            "        [ 9., 12.]])\n",
            "These are not compatible for matrix multiplication, but transposing one of these will favor.\n",
            "tensor([[ 7.,  8.,  9.],\n",
            "        [10., 11., 12.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The operation works when tensor_B is transposed\n",
        "print(f\"Original shapes: tensor_A = {tensor_A.shape}, tensor_B = {tensor_B.shape}\\n\")\n",
        "print(f\"New shapes: tensor_A = {tensor_A.shape} (same as above), tensor_B.T = {tensor_B.T.shape}\\n\")\n",
        "print(f\"Multiplying: {tensor_A.shape} * {tensor_B.T.shape} <- inner dimensions match\\n\")\n",
        "print(\"Output:\\n\")\n",
        "output = torch.matmul(tensor_A, tensor_B.T)\n",
        "print(output)\n",
        "print(f\"\\nOutput shape: {output.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bNvB4qs1Tukh",
        "outputId": "2a97835c-b797-414f-cc08-c42f75a903fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original shapes: tensor_A = torch.Size([3, 2]), tensor_B = torch.Size([3, 2])\n",
            "\n",
            "New shapes: tensor_A = torch.Size([3, 2]) (same as above), tensor_B.T = torch.Size([2, 3])\n",
            "\n",
            "Multiplying: torch.Size([3, 2]) * torch.Size([2, 3]) <- inner dimensions match\n",
            "\n",
            "Output:\n",
            "\n",
            "tensor([[ 27.,  30.,  33.],\n",
            "        [ 61.,  68.,  75.],\n",
            "        [ 95., 106., 117.]])\n",
            "\n",
            "Output shape: torch.Size([3, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# torch.mm is a shortcut for matmul\n",
        "torch.mm(tensor_A, tensor_B.T)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tYrqNd7HTzzj",
        "outputId": "1f35ba0e-9a59-416b-d75f-540900d66229"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 27.,  30.,  33.],\n",
              "        [ 61.,  68.,  75.],\n",
              "        [ 95., 106., 117.]])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Neural networks are full of matrix multiplications and dot products.\n",
        "\n",
        "The `torch.nn.Linear()` module, also known as a feed-forward layer or fully connected layer, implements a matrix multiplication between an input `x` and a weights matrix `A`.\n",
        "\n",
        "$$ y = x\\cdot{A^T} + b $$\n",
        "\n",
        "Where:\n",
        "\n",
        "`x` is the input to the layer (deep learning is a stack of layers like `torch.nn.Linear()` and others on top of each other).\n",
        "\n",
        "`A` is the weights matrix created by the layer, this starts out as random numbers that get adjusted as a neural network learns to better represent patterns in the data (notice the \"`T`\", that's because the weights matrix gets transposed).\n",
        "\n",
        "Note: You might also often see `W` or another letter like `X` used to showcase the weights matrix.\n",
        "\n",
        "`b` is the bias term used to slightly offset the weights and inputs.\n",
        "\n",
        "`y` is the output (a manipulation of the input in the hopes to discover patterns in it)."
      ],
      "metadata": {
        "id": "TUlgr6JHTAPx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Since the linear layer starts with a random weights matrix, let's make it reproducible\n",
        "torch.manual_seed(42)\n",
        "# This uses matrix multiplication\n",
        "linear = torch.nn.Linear(in_features=2, # in_features = matches inner dimension of input\n",
        "                         out_features=6) # out_features = describes outer value\n",
        "x = torch.tensor([[1, 2],\n",
        "                  [3, 4],\n",
        "                  [5, 6]], dtype=torch.float32) # shape of this tensor is (3, 2)\n",
        "output = linear(x)\n",
        "print(f\"Input shape: {x.shape}\\n\")\n",
        "print(f\"Output:\\n{output}\\n\\nOutput shape: {output.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hIVSvBHWS7Hj",
        "outputId": "5c6c8e6c-8fb6-4e2c-a7b3-85b55766579a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape: torch.Size([3, 2])\n",
            "\n",
            "Output:\n",
            "tensor([[2.2368, 1.2292, 0.4714, 0.3864, 0.1309, 0.9838],\n",
            "        [4.4919, 2.1970, 0.4469, 0.5285, 0.3401, 2.4777],\n",
            "        [6.7469, 3.1648, 0.4224, 0.6705, 0.5493, 3.9716]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "\n",
            "Output shape: torch.Size([3, 6])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finding the min, max, mean, sum, etc (aggregation)"
      ],
      "metadata": {
        "id": "zuPFAELjWBL_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.arange(0, 100, 10)\n",
        "print(f\"Minimum: {x.min()}\")\n",
        "print(f\"Maximum: {x.max()}\")\n",
        "# print(f\"Mean: {x.mean()}\") # this will error because mean expects the values to be of a float datatype.\n",
        "print(f\"Mean: {x.type(torch.float32).mean()}\") # won't work without float datatype\n",
        "print(f\"Sum: {x.sum()}\")\n",
        "\n",
        "print(f\"Index where max value occurs: {x.argmax()}\")\n",
        "print(f\"Index where min value occurs: {x.argmin()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N7KIpg3sVHli",
        "outputId": "35b51032-7c9e-4122-ca81-176d08dd56c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Minimum: 0\n",
            "Maximum: 90\n",
            "Mean: 45.0\n",
            "Sum: 450\n",
            "Index where max value occurs: 9\n",
            "Index where min value occurs: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can change the datatypes of tensors using `torch.Tensor.type(dtype=None)` where the dtype parameter is the datatype you'd like to use."
      ],
      "metadata": {
        "id": "9E-jBiCWW6c_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an int8 tensor\n",
        "print(x, x.dtype)\n",
        "tensor_int8 = x.type(torch.int8)\n",
        "tensor_int8"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B_JZlMcFWRtZ",
        "outputId": "d2a21ff6-c5dc-4ba8-bb65-8c0abefe0aa0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90]) torch.int64\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90], dtype=torch.int8)"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mobile-based neural networks often operate with 8-bit integers, smaller and faster to run but less accurate than their float32 counterparts.\n",
        "\n",
        "### Reshaping, stacking, squeezing and unsqueezing\n",
        "\n",
        "`torch.reshape(input, shape)`\t -> Reshapes input to shape (if compatible), can also use `torch.Tensor.reshape()`.\n",
        "\n",
        "`Tensor.view(shape)` -> Returns a view of the original tensor in a different shape but shares the same data as the original tensor.\n",
        "\n",
        "`torch.stack(tensors, dim=0)` -> Concatenates a sequence of tensors along a new dimension (dim), all tensors must be same size.\n",
        "\n",
        "`torch.squeeze(input)` -> Squeezes input to remove all the dimenions with value 1.\n",
        "\n",
        "`torch.unsqueeze(input, dim)` -> Returns input with a dimension value of 1 added at dim.\n",
        "\n",
        "`torch.permute(input, dims)` -> Returns a view of the original input with its dimensions permuted (rearranged) to dims."
      ],
      "metadata": {
        "id": "blxYki6WXrnV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a tensor\n",
        "import torch\n",
        "x = torch.arange(1., 9.)\n",
        "x, x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0W0A_UjnXfaR",
        "outputId": "04f24b89-d8a1-4996-d7b4-6d44823d8014"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([1., 2., 3., 4., 5., 6., 7., 8.]), torch.Size([8]))"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshape to a different dimension this time\n",
        "x_reshaped = x.reshape(2, 4)\n",
        "x_reshaped, x_reshaped.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eBgvA3ozYi8Y",
        "outputId": "7cd2cec0-1331-410f-b477-7e08e9f89c94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[1., 2., 3., 4.],\n",
              "         [5., 6., 7., 8.]]),\n",
              " torch.Size([2, 4]))"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Add an extra dimension\n",
        "x_reshaped = x.reshape(1, 8)\n",
        "x_reshaped, x_reshaped.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Da09jdS9YhhA",
        "outputId": "0724150c-8aa0-4fcc-86b4-b8959fa96d4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[1., 2., 3., 4., 5., 6., 7., 8.]]), torch.Size([1, 8]))"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Change view (keeps same data as original but changes view)\n",
        "# See more: https://stackoverflow.com/a/54507446/7900723\n",
        "z = x.view(8, 1)\n",
        "z, z.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rRSJz0HVYs3o",
        "outputId": "235d517c-01d0-47c7-c373-66850b69d23d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[1.],\n",
              "         [2.],\n",
              "         [3.],\n",
              "         [4.],\n",
              "         [5.],\n",
              "         [6.],\n",
              "         [7.],\n",
              "         [8.]]),\n",
              " torch.Size([8, 1]))"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Changing the view of a tensor with torch.view() really only creates a new view of the same tensor, therefore changing z changes x."
      ],
      "metadata": {
        "id": "CppI9YixZAx-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Changing z changes x\n",
        "z[3] = 0\n",
        "z, x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nR_w9NGgY41I",
        "outputId": "77e6a4a9-e861-4054-edb5-e93ff21c6542"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[1.],\n",
              "         [2.],\n",
              "         [3.],\n",
              "         [0.],\n",
              "         [5.],\n",
              "         [6.],\n",
              "         [7.],\n",
              "         [8.]]),\n",
              " tensor([1., 2., 3., 0., 5., 6., 7., 8.]))"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If we wanted to stack our new tensor on top of itself 4 times, we could do so with `torch.stack()`."
      ],
      "metadata": {
        "id": "7gScpc2tZ25F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_stacked = torch.stack([x, x, x, x], dim=-2) # Dimension expected to be in range of [-2, 1], 0 and -2 for rows, 1 and -1 for columns\n",
        "x_stacked"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0UxEfgiXZECH",
        "outputId": "767f95cf-5ab9-468c-d01b-a5cb2e6d9b5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 2., 3., 0., 5., 6., 7., 8.],\n",
              "        [1., 2., 3., 0., 5., 6., 7., 8.],\n",
              "        [1., 2., 3., 0., 5., 6., 7., 8.],\n",
              "        [1., 2., 3., 0., 5., 6., 7., 8.]])"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`torch.squeeze()` removes all single dimensions from a tensor."
      ],
      "metadata": {
        "id": "zFU47EdzadCH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Previous tensor: {x_reshaped}\")\n",
        "print(f\"Previous shape: {x_reshaped.shape}\")\n",
        "\n",
        "# Remove extra dimension from x_reshaped\n",
        "x_squeezed = x_reshaped.squeeze()\n",
        "print(f\"\\nNew tensor: {x_squeezed}\")\n",
        "print(f\"New shape: {x_squeezed.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "De_46UinZ82v",
        "outputId": "020b02ab-b63d-4459-ca45-330b246eda27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Previous tensor: tensor([[1., 2., 3., 0., 5., 6., 7., 8.]])\n",
            "Previous shape: torch.Size([1, 8])\n",
            "\n",
            "New tensor: tensor([1., 2., 3., 0., 5., 6., 7., 8.])\n",
            "New shape: torch.Size([8])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "And to do the reverse of `torch.squeeze()` you can use `torch.unsqueeze()` to add a dimension value of 1 at a specific index."
      ],
      "metadata": {
        "id": "T-R4ktgBaroG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Previous tensor: {x_squeezed}\")\n",
        "print(f\"Previous shape: {x_squeezed.shape}\")\n",
        "\n",
        "# Add an extra dimension with unsqueeze\n",
        "x_unsqueezed = x_squeezed.unsqueeze(dim=0)\n",
        "print(f\"\\nNew tensor: {x_unsqueezed}\")\n",
        "print(f\"New shape: {x_unsqueezed.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j6gR5-5Raaj2",
        "outputId": "c0be483d-b6c9-41f6-9db9-04ff25e4dcfb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Previous tensor: tensor([1., 2., 3., 0., 5., 6., 7., 8.])\n",
            "Previous shape: torch.Size([8])\n",
            "\n",
            "New tensor: tensor([[1., 2., 3., 0., 5., 6., 7., 8.]])\n",
            "New shape: torch.Size([1, 8])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can also rearrange the order of axes values with `torch.permute(input, dims)`, where the input gets turned into a view with new dims."
      ],
      "metadata": {
        "id": "E96yG9sMbGe_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create tensor with specific shape\n",
        "x_original = torch.rand(size=(224, 224, 3))\n",
        "\n",
        "# Permute the original tensor to rearrange the axis order\n",
        "x_permuted = x_original.permute(2, 0, 1) # shifts axis 0->1, 1->2, 2->0\n",
        "\n",
        "print(f\"Previous shape: {x_original.shape}\")\n",
        "print(f\"New shape: {x_permuted.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YucwHbjNazDn",
        "outputId": "be2642a4-a519-4f77-bd87-ca67940ca289"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Previous shape: torch.Size([224, 224, 3])\n",
            "New shape: torch.Size([3, 224, 224])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`torch.permute()` returns a view, therefore changing any values inside the permuted tensor will also change values inside the original tensor.\n",
        "\n",
        "Indexing a tensor:"
      ],
      "metadata": {
        "id": "JUgexMvdbPv4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.arange(1, 10).reshape(1, 3, 3)\n",
        "x, x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "awDiiH3lbXSe",
        "outputId": "53eaf7fe-61dd-4b30-9236-0c96e7d9b840"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[1, 2, 3],\n",
              "          [4, 5, 6],\n",
              "          [7, 8, 9]]]),\n",
              " torch.Size([1, 3, 3]))"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"First square bracket:\\n{x[0]}\")\n",
        "print(f\"Second square bracket: {x[0][0]}\")\n",
        "print(f\"Third square bracket: {x[0][0][0]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lfWJX_8ubnXu",
        "outputId": "fdfd802a-2b57-4b37-c53d-ef94263ef0b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First square bracket:\n",
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6],\n",
            "        [7, 8, 9]])\n",
            "Second square bracket: tensor([1, 2, 3])\n",
            "Third square bracket: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can also use `:` to specify \"all values in this dimension\" and then use a comma (`,`) to add another dimension."
      ],
      "metadata": {
        "id": "lHgY2YESbs8F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get all values of 0th dimension and the 0 index of 1st dimension\n",
        "print(x[:, 0])\n",
        "# Get all values of 0th & 1st dimensions but only index 1 of 2nd dimension, prints the middle column of the tensor\n",
        "print(x[:, :, 1])\n",
        "# Get all values of the 0 dimension but only the 1 index value of the 1st and 2nd dimension\n",
        "print(x[:, 1, 1])\n",
        "# Get index 0 of 0th and 1st dimension and all values of 2nd dimension\n",
        "print(x[0, 0, :]) # same as x[0][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X13vIAKVbpoW",
        "outputId": "506316e6-58b2-4600-d07f-b75db8b7e0e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1, 2, 3]])\n",
            "tensor([[2, 5, 8]])\n",
            "tensor([5])\n",
            "tensor([1, 2, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "NumPy to PyTorch:\n",
        "\n",
        "`torch.from_numpy(ndarray)` - NumPy array -> PyTorch tensor.\n",
        "\n",
        "`torch.Tensor.numpy()` - PyTorch tensor -> NumPy array."
      ],
      "metadata": {
        "id": "MJkEYGx-cusN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# NumPy array to tensor\n",
        "import torch\n",
        "import numpy as np\n",
        "array = np.arange(1.0, 8.0)\n",
        "tensor = torch.from_numpy(array)\n",
        "array, tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2hWgC1LGb6zW",
        "outputId": "e79c6325-c2a5-43d9-e8ec-a49eedb3338c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([1., 2., 3., 4., 5., 6., 7.]),\n",
              " tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64))"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "By default, NumPy arrays are created with the datatype float64 and if you convert it to a PyTorch tensor, it'll keep the same datatype (as above).\n",
        "\n",
        "However, many PyTorch calculations default to using float32.\n",
        "\n",
        "So if you want to convert your NumPy array (float64) -> PyTorch tensor (float64) -> PyTorch tensor (float32), you can use `tensor = torch.from_numpy(array).type(torch.float32)`."
      ],
      "metadata": {
        "id": "HFbhglxedDym"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tensor to NumPy array\n",
        "tensor = torch.ones(7) # create a tensor of ones with dtype=float32\n",
        "numpy_tensor = tensor.numpy() # will be dtype=float32 unless changed\n",
        "tensor, numpy_tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cSv1ccM2dAyW",
        "outputId": "de692a01-af6e-4348-dfef-edc0723ffd8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([1., 1., 1., 1., 1., 1., 1.]),\n",
              " array([1., 1., 1., 1., 1., 1., 1.], dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Reproducibility\n",
        "\n",
        "To get similar results during multiple experiments."
      ],
      "metadata": {
        "id": "Yz5btokm9_FV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_A = torch.rand(size = (3, 4))\n",
        "tensor_B = torch.rand(size = (3, 4))\n",
        "\n",
        "print(tensor_A)\n",
        "print(tensor_B)\n",
        "print(tensor_A == tensor_B)"
      ],
      "metadata": {
        "id": "4cQ84I2xdUn9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47a0ce8f-ca2b-4592-90e5-6496813e7988"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.5221, 0.4282, 0.5457, 0.1361],\n",
            "        [0.3974, 0.4310, 0.4273, 0.3377],\n",
            "        [0.4408, 0.2849, 0.6686, 0.0769]])\n",
            "tensor([[1.9903e-01, 6.1995e-01, 3.0576e-01, 1.1145e-01],\n",
            "        [8.8489e-04, 8.8991e-01, 2.0506e-01, 5.3740e-01],\n",
            "        [3.0945e-01, 9.8135e-01, 5.3891e-01, 7.0623e-01]])\n",
            "tensor([[False, False, False, False],\n",
            "        [False, False, False, False],\n",
            "        [False, False, False, False]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "But what if you wanted to create two random tensors with the same values.\n",
        "\n",
        "That's where `torch.manual_seed(seed)` comes in, where seed is an integer (like `42` but it could be anything) that flavours the randomness."
      ],
      "metadata": {
        "id": "ECIJwlBJ-SpL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "RANDOM_SEED=42 # try changing this to different values and see what happens to the numbers below\n",
        "torch.manual_seed(seed=RANDOM_SEED)\n",
        "random_tensor_C = torch.rand(3, 4)\n",
        "\n",
        "# Have to reset the seed every time a new rand() is called\n",
        "# Without this, tensor_D would be different to tensor_C\n",
        "torch.manual_seed(seed=42) # try commenting this line out and seeing what happens\n",
        "random_tensor_D = torch.rand(3, 4)\n",
        "\n",
        "print(f\"Tensor C:\\n{random_tensor_C}\\n\")\n",
        "print(f\"Tensor D:\\n{random_tensor_D}\\n\")\n",
        "random_tensor_C == random_tensor_D"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZgT5chZC94aL",
        "outputId": "8332251e-a342-4284-e7cf-67bd13c32e03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor C:\n",
            "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
            "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
            "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
            "\n",
            "Tensor D:\n",
            "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
            "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
            "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[True, True, True, True],\n",
              "        [True, True, True, True],\n",
              "        [True, True, True, True]])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Seed sets the randomness, if you have the same seed, the randomness in that seed is 0.\n",
        "\n",
        "[The PyTorch Reproducibility Documentation](https://pytorch.org/docs/stable/notes/randomness.html)\n",
        "\n",
        "Results may not be reproducible between CPU and GPU executions, even when using identical seeds."
      ],
      "metadata": {
        "id": "oh-Lww-M_ATG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using GPU with PyTorch to make computations"
      ],
      "metadata": {
        "id": "dhW7mCdyAHTX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To set up PyTorch on AWS or your own PC and use an available GPU, follow [this link](https://www.learnpytorch.io/00_pytorch_fundamentals/#1-getting-a-gpu).\n",
        "\n",
        "To access GPU on Apple devices, follow [this link](https://www.learnpytorch.io/00_pytorch_fundamentals/#21-getting-pytorch-to-run-on-apple-silicon)."
      ],
      "metadata": {
        "id": "XrFcxDP7A23b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for a GPU\n",
        "import torch\n",
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_f2MJtv__Fni",
        "outputId": "f3d2a33b-0c6f-4e5f-b6d6-5e9ab87999b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ],
      "metadata": {
        "id": "qHAhuSgZATnS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = \"cuda\" # Use NVIDIA GPU (if available)\n",
        "elif torch.backends.mps.is_available():\n",
        "    device = \"mps\" # Use Apple Silicon GPU (if available)\n",
        "else:\n",
        "    device = \"cpu\" # Default to CPU if no GPU is available\n",
        "\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6W4GA_TYBYNd",
        "outputId": "0581323d-63ac-4ac8-dcc3-a4d5f58b9731"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In PyTorch, it's best practice to write device agnostic code. This means code that'll run on CPU (always available) or GPU (if available).\n",
        "\n",
        "Knowing the number of GPUs PyTorch has access to is helpful incase you wanted to run a specific process on one GPU and another process on another (PyTorch also has features to let you run a process across all GPUs)."
      ],
      "metadata": {
        "id": "doHKZMYiAo8V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Counting the number of GPUs available:\n",
        "torch.cuda.device_count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kf_APjwCAok5",
        "outputId": "7a0ad180-8136-4f4b-ecc2-637202b861ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can put tensors (and models, we'll see this later) on a specific device by calling `to(device)` on them. Where device is the target device you'd like the tensor (or model) to go to.\n",
        "\n",
        "To change an existing tensor’s `torch.device` and/or `torch.dtype`, consider using `to()` method on the tensor."
      ],
      "metadata": {
        "id": "Ul8inoq7Bms4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor = torch.tensor([1, 2, 3]) # Default on CPU\n",
        "\n",
        "print(tensor, tensor.device)\n",
        "\n",
        "tensor_on_gpu = tensor.to(device)\n",
        "tensor_on_gpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ViRsedqBo25",
        "outputId": "28d3f780-182c-47a9-df65-35c7c0c291b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 2, 3]) cpu\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2, 3], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice the second tensor has `device='cuda:0'`, this means it's stored on the 0th GPU available (GPUs are 0 indexed, if two GPUs were available, they'd be '`cuda:0`' and '`cuda:1`' respectively, up to '`cuda:n`').\n",
        "\n",
        "You might want to move the tensor back on the CPU because numpy does not work with tensors on the GPU."
      ],
      "metadata": {
        "id": "HKl_DiJmB4LH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Copy the tensor back to cpu\n",
        "tensor_back_on_cpu = tensor_on_gpu.cpu().numpy()\n",
        "tensor_back_on_cpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZjFsHg-zBvvJ",
        "outputId": "e11f7b5b-089d-4fef-aa10-5d6b257d700f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This tensor is still on the GPUs memory\n",
        "print(tensor_on_gpu)\n",
        "\n",
        "# To check if any tensor is on the GPU or not\n",
        "print(tensor_on_gpu.is_cuda)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0yPePDmUCS5p",
        "outputId": "bffb679f-3e2f-4c36-97bf-a3660fcefa02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 2, 3], device='cuda:0')\n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating tensors with gradients for automatic differentiation\n",
        "\n",
        "A tensor can be created with `requires_grad=True` so that `torch.autograd` records operations on them for automatic differentiation."
      ],
      "metadata": {
        "id": "lP559s2WD2Yk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor([[1., -1.], [1., 1.]], requires_grad=True)\n",
        "out = x.pow(2).sum()\n",
        "out.backward()\n",
        "x.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iKdy27whEAtI",
        "outputId": "f87123ce-6bb4-4609-ffac-8106e4baa42a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 2., -2.],\n",
              "        [ 2.,  2.]])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For all functions and attributes of a tensor, check [this link](https://pytorch.org/docs/stable/tensors.html#id9) out."
      ],
      "metadata": {
        "id": "84WUiK9bFycH"
      }
    }
  ]
}